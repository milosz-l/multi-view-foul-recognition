{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- %env PYTORCH_ENABLE_MPS_FALLBACK=1 # MPS fallback for GPUs that don't support it\n",
    "- %env export CUDA_VISIBLE_DEVICES=\"\" # completely disable GPU and run on CPU only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_ENABLE_MPS_FALLBACK=1\n",
      "env: CUDA_VISIBLE_DEVICES=\"\"\n"
     ]
    }
   ],
   "source": [
    "%env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "%env CUDA_VISIBLE_DEVICES=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "\n",
    "\n",
    "from SoccerNet.Evaluation.MV_FoulRecognition import evaluate\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from src.training import TrainingConfig\n",
    "from src.dataset import MultiViewDataset\n",
    "from src.model import LitMVNNetwork, get_pre_model\n",
    "from src.loss import get_criterion\n",
    "from src.eval import save_evaluation_file\n",
    "from datetime import datetime\n",
    "import os\n",
    "from src.augment import get_augmentation\n",
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmilosz-l\u001b[0m (\u001b[33mwut-zzsn\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "start_frame = 0\n",
    "end_frame = 64\n",
    "fps = 25\n",
    "num_views = 5\n",
    "pre_model = \"s3d\"\n",
    "max_num_worker = 0\n",
    "batch_size = 2\n",
    "data_aug = False\n",
    "pooling_type = \"max\"\n",
    "weight_decay = 0.001\n",
    "step_size = 3\n",
    "gamma = 0.1\n",
    "LR = 0.01\n",
    "weighted_loss = False\n",
    "data_aug = False\n",
    "\n",
    "training_config = TrainingConfig(\n",
    "    start_frame=start_frame,\n",
    "    end_frame=end_frame,\n",
    "    fps=fps,\n",
    "    num_views=num_views,\n",
    "    pre_model=pre_model,\n",
    "    max_num_worker=max_num_worker,\n",
    "    batch_size=batch_size,\n",
    "    data_aug=data_aug,\n",
    "    pooling_type=pooling_type,\n",
    "    weight_decay=weight_decay,\n",
    "    step_size=step_size,\n",
    "    gamma=gamma,\n",
    "    LR=LR,\n",
    "    weighted_loss=weighted_loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/milosz/Documents/PW_sem9/ZZSN/multi-view-foul-recognition/wandb/run-20240413_194128-05u97z51</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wut-zzsn/ZZSN%20multi-view-foul-recognition/runs/05u97z51' target=\"_blank\">laced-frost-3</a></strong> to <a href='https://wandb.ai/wut-zzsn/ZZSN%20multi-view-foul-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wut-zzsn/ZZSN%20multi-view-foul-recognition' target=\"_blank\">https://wandb.ai/wut-zzsn/ZZSN%20multi-view-foul-recognition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wut-zzsn/ZZSN%20multi-view-foul-recognition/runs/05u97z51' target=\"_blank\">https://wandb.ai/wut-zzsn/ZZSN%20multi-view-foul-recognition/runs/05u97z51</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/wut-zzsn/ZZSN%20multi-view-foul-recognition/runs/05u97z51?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x16c1cf6a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"ZZSN multi-view-foul-recognition\", config=training_config.model_dump()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/mvfouls\"\n",
    "predictions_output_dir = \"outputs\"\n",
    "\n",
    "transform_aug = get_augmentation(training_config.data_aug)\n",
    "transforms_model = get_pre_model(training_config.pre_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2319\n"
     ]
    }
   ],
   "source": [
    "dataset_Train = MultiViewDataset(\n",
    "    path=path,\n",
    "    start=start_frame,\n",
    "    end=end_frame,\n",
    "    fps=fps,\n",
    "    split=\"Train\",\n",
    "    num_views=5,\n",
    "    transform=transform_aug,\n",
    "    transform_model=transforms_model,\n",
    ")\n",
    "\n",
    "train_size = int(0.7 * len(dataset_Train))\n",
    "val_size = len(dataset_Train) - train_size\n",
    "\n",
    "train_set, val_set = random_split(dataset_Train, [train_size, val_size])\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=max_num_worker,\n",
    "    pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=max_num_worker,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"datasets\"\n",
    "\n",
    "dataset_Test = MultiViewDataset(\n",
    "    path=path,\n",
    "    start=start_frame,\n",
    "    end=end_frame,\n",
    "    fps=fps,\n",
    "    split=\"Test\",\n",
    "    num_views=5,\n",
    "    transform_model=transforms_model,\n",
    ")\n",
    "\n",
    "\n",
    "# dataset_Chall = MultiViewDataset(\n",
    "#     path=path,\n",
    "#     start=start_frame,\n",
    "#     end=end_frame,\n",
    "#     fps=fps,\n",
    "#     split=\"Chall\",\n",
    "#     num_views=5,\n",
    "#     transform_model=transforms_model,\n",
    "# )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset_Test,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=max_num_worker,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "# chall_loader = torch.utils.data.DataLoader(\n",
    "#     dataset_Chall,\n",
    "#     batch_size=1,\n",
    "#     shuffle=False,\n",
    "#     num_workers=max_num_worker,\n",
    "#     pin_memory=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = get_criterion(weighted_loss, dataset_train=dataset_Train)\n",
    "model = LitMVNNetwork(\n",
    "    pre_model=pre_model,\n",
    "    pooling_type=pooling_type,\n",
    "    criterion=criterion,\n",
    "    config=training_config,\n",
    ")\n",
    "job_id = str(datetime.now())\n",
    "wand_logger = WandbLogger(log_model=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/milosz/opt/miniconda3/envs/zzsn/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:391: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | model | MVNetwork | 9.0 M \n",
      "------------------------------------\n",
      "9.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.0 M     Total params\n",
      "35.875    Total estimated model params size (MB)\n",
      "/Users/milosz/opt/miniconda3/envs/zzsn/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/milosz/opt/miniconda3/envs/zzsn/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/3 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milosz/opt/miniconda3/envs/zzsn/lib/python3.10/site-packages/torchvision/io/video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n",
      "  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n",
      "/Users/milosz/opt/miniconda3/envs/zzsn/lib/python3.10/site-packages/torch/nn/functional.py:882: UserWarning: The operator 'aten::max_pool3d_with_indices' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  return torch.max_pool3d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/Users/milosz/opt/miniconda3/envs/zzsn/lib/python3.10/site-packages/lightning/pytorch/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  33%|███▎      | 1/3 [00:54<01:49,  0.02it/s, v_num=7z51, train_step_loss=46.20, train_epoch_loss=46.10]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milosz/opt/miniconda3/envs/zzsn/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(limit_train_batches=3, max_epochs=num_epochs, logger=wand_logger)\n",
    "trainer.fit(model=model, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/251 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m test_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m chall_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchall_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m test_prediction_file \u001b[38;5;241m=\u001b[39m \u001b[43msave_evaluation_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions_output_dir\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m chall_prediction_file \u001b[38;5;241m=\u001b[39m save_evaluation_file(\n\u001b[1;32m     10\u001b[0m     chall_loader, model\u001b[38;5;241m=\u001b[39mmodel, set_name\u001b[38;5;241m=\u001b[39mchall_set, output_dir\u001b[38;5;241m=\u001b[39mpredictions_output_dir\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/PW_sem9/ZZSN/multi-view-foul-recognition/src/eval.py:27\u001b[0m, in \u001b[0;36msave_evaluation_file\u001b[0;34m(dataloader, model, set_name, output_dir)\u001b[0m\n\u001b[1;32m     23\u001b[0m actions \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, mvclips, action \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[0;32m---> 27\u001b[0m     mvclips \u001b[38;5;241m=\u001b[39m \u001b[43mmvclips\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     28\u001b[0m     outputs_offence_severity, outputs_action, _ \u001b[38;5;241m=\u001b[39m model(mvclips)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(action) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/zzsn/lib/python3.10/site-packages/torch/cuda/__init__.py:284\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "os.makedirs(predictions_output_dir, exist_ok=True)\n",
    "\n",
    "test_set = f\"test_{job_id}\"\n",
    "chall_set = f\"chall_{job_id}\"\n",
    "\n",
    "test_prediction_file = save_evaluation_file(\n",
    "    test_loader, model=model, set_name=test_set, output_dir=predictions_output_dir\n",
    ")\n",
    "chall_prediction_file = save_evaluation_file(\n",
    "    chall_loader, model=model, set_name=chall_set, output_dir=predictions_output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "test_results = evaluate(\n",
    "    os.path.join(path, \"Test\", \"annotations.json\"), test_prediction_file\n",
    ")\n",
    "wandb.log(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_action</td><td>▁</td></tr><tr><td>accuracy_offence_severity</td><td>▁</td></tr><tr><td>balanced_accuracy_action</td><td>▁</td></tr><tr><td>balanced_accuracy_offence_severity</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▅▅██</td></tr><tr><td>leaderboard_value</td><td>▁</td></tr><tr><td>train_epoch_loss</td><td>▁█▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▃▃▃▃▃▅▅▄▅▅██</td></tr><tr><td>val_epoch_loss</td><td>▁  </td></tr><tr><td>val_step_loss</td><td>▁▂█      </td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_action</td><td>17.13147</td></tr><tr><td>accuracy_offence_severity</td><td>8.36653</td></tr><tr><td>balanced_accuracy_action</td><td>12.5</td></tr><tr><td>balanced_accuracy_offence_severity</td><td>25.0</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>leaderboard_value</td><td>18.75</td></tr><tr><td>train_epoch_loss</td><td>30.75137</td></tr><tr><td>trainer/global_step</td><td>14</td></tr><tr><td>val_epoch_loss</td><td>nan</td></tr><tr><td>val_step_loss</td><td>nan</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-plasma-4</strong> at: <a href='https://wandb.ai/adamsebastiangorski/ZZSN%20multi-view-foul-recognition/runs/tj0gbx9q/workspace' target=\"_blank\">https://wandb.ai/adamsebastiangorski/ZZSN%20multi-view-foul-recognition/runs/tj0gbx9q/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240403_153108-tj0gbx9q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
